{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vfPIxwiSLfmh"
      },
      "id": "vfPIxwiSLfmh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"left\">\n",
        "    <img width=\"640\" src=\"https://highlighter-public.s3.ap-southeast-2.amazonaws.com/web/assets/Highlighter_Logo_Primary_Horizontal_RGB.png\" alt=\"Highlighter logo\">\n",
        "</div>\n",
        "\n",
        "# Create Assessments\n",
        "\n",
        "An `assessment` is a collections of *attributes* associated with a `data_file`. In the follwing example we're dealing with a very small object detection dataset in the common `Coco` format. So each `data_file` is an image in the dataset and the collection of bounding boxes associated with each image is the `assessment`.\n",
        "\n",
        "In the real world `assessment`s can be created in several different ways. This notebook demos a few common usecases:\n",
        "\n",
        "  - You have an existing dataaset in Coco format, you wish to upload the image and the annotations.\n",
        "  - You have an existing dataset in some custom format the is not currently supported by the `highlighter-sdk`\n",
        "  - You have some local process like a deep learning model you run locally to produce outputs you wish to upload as `assessment`s in Highligher\n",
        "\n",
        "---\n",
        "\n",
        "First we need to install the `highlighter-sdk`"
      ],
      "metadata": {
        "id": "ZDTdnWdTJKt0"
      },
      "id": "ZDTdnWdTJKt0"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install highlighter-sdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZEcegPiHUCx",
        "outputId": "f1df457c-0829-4a4d-dd48-02040239698b"
      },
      "id": "wZEcegPiHUCx",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting highlighter-sdk\n",
            "  Downloading highlighter_sdk-0.5.0.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp~=3.7 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (3.9.3)\n",
            "Collecting boto3~=1.26.30 (from highlighter-sdk)\n",
            "  Downloading boto3-1.26.165-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,<9,>=7 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (8.1.7)\n",
            "Collecting colorama~=0.4.4 (from highlighter-sdk)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting fastavro~=1.8 (from highlighter-sdk)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gql~=3.4.0 (from highlighter-sdk)\n",
            "  Downloading gql-3.4.1-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab~=3.2 (from highlighter-sdk)\n",
            "  Downloading jupyterlab-3.6.7-py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python~=4.7 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (4.8.0.76)\n",
            "Requirement already satisfied: pandas~=1.0 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (1.5.3)\n",
            "Requirement already satisfied: pillow>=6.0 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (9.4.0)\n",
            "Requirement already satisfied: pooch~=1.5 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (1.8.1)\n",
            "Collecting pydantic<2.0,>=1.6 (from highlighter-sdk)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic~=0.4.0 (from highlighter-sdk)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pyyaml>=5.0 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (6.0.1)\n",
            "Collecting requests-toolbelt (from highlighter-sdk)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests~=2.22 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (2.31.0)\n",
            "Requirement already satisfied: shapely>2.0.1 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (2.0.3)\n",
            "Requirement already satisfied: tables~=3.7 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (3.8.0)\n",
            "Requirement already satisfied: tqdm~=4.0 in /usr/local/lib/python3.10/dist-packages (from highlighter-sdk) (4.66.2)\n",
            "Collecting websockets~=10.0 (from highlighter-sdk)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.7->highlighter-sdk) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.7->highlighter-sdk) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.7->highlighter-sdk) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.7->highlighter-sdk) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.7->highlighter-sdk) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.7->highlighter-sdk) (4.0.3)\n",
            "Collecting botocore<1.30.0,>=1.29.165 (from boto3~=1.26.30->highlighter-sdk)\n",
            "  Downloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3~=1.26.30->highlighter-sdk)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3~=1.26.30->highlighter-sdk)\n",
            "  Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-core<3.3,>=3.2 (from gql~=3.4.0->highlighter-sdk)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff<3.0,>=1.11.1 (from gql~=3.4.0->highlighter-sdk)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (24.0)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (6.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (5.7.2)\n",
            "Collecting jupyterlab-server~=2.19 (from jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading jupyterlab_server-2.25.4-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (1.24.0)\n",
            "Collecting jupyter-ydoc~=0.2.4 (from jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading jupyter_ydoc-0.2.5-py3-none-any.whl (6.2 kB)\n",
            "Collecting jupyter-server-ydoc~=0.8.0 (from jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading jupyter_server_ydoc-0.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: nbclassic in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (1.0.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (6.5.5)\n",
            "Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (3.1.3)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab~=3.2->highlighter-sdk) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python~=4.7->highlighter-sdk) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.0->highlighter-sdk) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.0->highlighter-sdk) (2023.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch~=1.5->highlighter-sdk) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0,>=1.6->highlighter-sdk) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.22->highlighter-sdk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.22->highlighter-sdk) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.22->highlighter-sdk) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.22->highlighter-sdk) (2024.2.2)\n",
            "Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables~=3.7->highlighter-sdk) (3.0.9)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables~=3.7->highlighter-sdk) (2.9.0)\n",
            "Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables~=3.7->highlighter-sdk) (2.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables~=3.7->highlighter-sdk) (9.0.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2~=2.0.0->tables~=3.7->highlighter-sdk) (1.0.8)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests~=2.22->highlighter-sdk)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.1->jupyterlab~=3.2->highlighter-sdk) (2.1.5)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (6.1.12)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (5.10.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.20.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.18.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (5.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (1.7.0)\n",
            "Collecting jupyter-server-fileid<1,>=0.6.0 (from jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading jupyter_server_fileid-0.9.1-py3-none-any.whl (16 kB)\n",
            "Collecting ypy-websocket<0.9.0,>=0.8.2 (from jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading ypy_websocket-0.8.4-py3-none-any.whl (10 kB)\n",
            "Collecting y-py<0.7.0,>=0.6.0 (from jupyter-ydoc~=0.2.4->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading y_py-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk) (2.14.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading json5-0.9.24-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk) (4.19.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab~=3.2->highlighter-sdk) (0.2.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab~=3.2->highlighter-sdk) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab~=3.2->highlighter-sdk) (5.5.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic->jupyterlab~=3.2->highlighter-sdk) (0.2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas~=1.0->highlighter-sdk) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab~=3.2->highlighter-sdk) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (1.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->jupyterlab~=3.2->highlighter-sdk) (0.8.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk) (0.18.0)\n",
            "Collecting jupyter-events>=0.5.0 (from jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (2.19.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->jupyterlab~=3.2->highlighter-sdk) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyterlab~=3.2->highlighter-sdk) (0.2.13)\n",
            "Collecting aiofiles<23,>=22.1.0 (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiosqlite<1,>=0.17.0 (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (21.2.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab~=3.2->highlighter-sdk) (2.21)\n",
            "Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk) (1.13)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab~=3.2->highlighter-sdk)\n",
            "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
            "Installing collected packages: y-py, websockets, urllib3, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-magic, python-json-logger, pydantic, jupyter-ydoc, jsonpointer, json5, jmespath, jedi, graphql-core, fqdn, fastavro, colorama, backoff, aiosqlite, aiofiles, ypy-websocket, gql, botocore, arrow, s3transfer, requests-toolbelt, isoduration, boto3, jupyter-events, jupyterlab-server, jupyter-server-fileid, jupyter-server-ydoc, jupyterlab, highlighter-sdk\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "Successfully installed aiofiles-22.1.0 aiosqlite-0.20.0 arrow-1.3.0 backoff-2.2.1 boto3-1.26.165 botocore-1.29.165 colorama-0.4.6 fastavro-1.9.4 fqdn-1.5.1 gql-3.4.1 graphql-core-3.2.3 highlighter-sdk-0.5.0.3 isoduration-20.11.0 jedi-0.19.1 jmespath-1.0.1 json5-0.9.24 jsonpointer-2.4 jupyter-events-0.10.0 jupyter-server-fileid-0.9.1 jupyter-server-ydoc-0.8.0 jupyter-ydoc-0.2.5 jupyterlab-3.6.7 jupyterlab-server-2.25.4 pydantic-1.10.14 python-json-logger-2.0.7 python-magic-0.4.27 requests-toolbelt-1.0.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 s3transfer-0.6.2 types-python-dateutil-2.9.0.20240316 uri-template-1.3.0 urllib3-1.26.18 websockets-10.4 y-py-0.6.2 ypy-websocket-0.8.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Download Sample Dataset"
      ],
      "metadata": {
        "id": "jnt5idmsL0KL"
      },
      "id": "jnt5idmsL0KL"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0",
      "metadata": {
        "tags": [],
        "id": "0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from uuid import uuid4\n",
        "import urllib\n",
        "import tarfile\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "\n",
        "import highlighter as hl\n",
        "from highlighter.datasets import ImageRecord, AttributeRecord, Dataset\n",
        "\n",
        "from IPython.display import display_html\n",
        "from itertools import chain,cycle\n",
        "\n",
        "def show_dataset(ds):\n",
        "    \"\"\"Helper to display Datasets nicely in the Notebook\n",
        "    \"\"\"\n",
        "    html_str=''\n",
        "    for df,title in zip([ds.annotations_df, ds.data_files_df], chain([\"Annotations\", \"Data Files\"],cycle(['</br>'])) ):\n",
        "        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
        "        html_str+=f'<h2 style=\"text-align: center;\">{title}</h2>'\n",
        "        html_str+=df.head(5).to_html().replace('table','table style=\"display:inline\"')\n",
        "        html_str+=f'<br> shape: {df.shape}</td></th>'\n",
        "    display_html(html_str,raw=True)\n",
        "\n",
        "\n",
        "SAMPLE_DATASET_URL = \"https://highlighter-public.s3.ap-southeast-2.amazonaws.com/simple-shapes-coco/simple_shapes_dataset.tar\"\n",
        "\n",
        "TEMP_DIR = Path(tempfile.mkdtemp())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1",
      "metadata": {
        "tags": [],
        "id": "1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_sample_data(temp_dir=TEMP_DIR):\n",
        "    dataset_path = TEMP_DIR / \"sample_dataset\"\n",
        "    coco_json = dataset_path / \"data.json\"\n",
        "    data_files_dir = dataset_path / \"images\"\n",
        "\n",
        "    if coco_json.exists():\n",
        "        print(f\"Existing data found at: {dataset_path}\")\n",
        "        return coco_json, data_files_dir\n",
        "\n",
        "    try:\n",
        "        # Download the tar file\n",
        "        filename = SAMPLE_DATASET_URL.split('/')[-1]\n",
        "        filepath = Path(temp_dir) / filename\n",
        "        urllib.request.urlretrieve(SAMPLE_DATASET_URL, filepath)\n",
        "\n",
        "        # Extract the tar file\n",
        "        with tarfile.open(filepath, 'r') as tar:\n",
        "            tar.extractall(temp_dir)\n",
        "\n",
        "        (Path(temp_dir) / filepath.stem).rename(dataset_path)\n",
        "        print(f\"File downloaded and extracted to: {dataset_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "\n",
        "    return coco_json, data_files_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "# Create a Dataset From A Supported Format\n",
        "\n",
        "Some common dataset formats can be read from out-of-the-box, and we plan to add more as time goes on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3",
        "outputId": "4a09d860-0cea-47cd-fef8-83ad1b9f8366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and extracted to: /tmp/tmp6z0dwgm0/sample_dataset\n"
          ]
        }
      ],
      "source": [
        "COCO_JSON, DATA_FILES_DIR = get_sample_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4",
      "metadata": {
        "tags": [],
        "id": "4"
      },
      "outputs": [],
      "source": [
        "ds = Dataset.read_coco(COCO_JSON)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "5",
        "outputId": "336bbf20-a0f6-4cec-ddbf-4e40f7f3023f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">Annotations</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_file_id</th>\n",
              "      <th>entity_id</th>\n",
              "      <th>attribute_id</th>\n",
              "      <th>attribute_name</th>\n",
              "      <th>value</th>\n",
              "      <th>confidence</th>\n",
              "      <th>extra_fields</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>06aa92af-7e51-4e8d-9d60-fec8c9c03b2b</td>\n",
              "      <td>df10b67d-b476-4c4d-acc2-c1deb5a0e4f4</td>\n",
              "      <td>object_class</td>\n",
              "      <td>rectangle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:52:10.749385'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>06aa92af-7e51-4e8d-9d60-fec8c9c03b2b</td>\n",
              "      <td>594fcdba-c3dc-4fad-b1c1-f5f537e1d16c</td>\n",
              "      <td>pixel_location</td>\n",
              "      <td>POLYGON ((468 484, 592 484, 592 615, 468 615, 468 484))</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:52:10.752612'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0a2c19be-9a40-47bd-8348-4db9afea62a6</td>\n",
              "      <td>df10b67d-b476-4c4d-acc2-c1deb5a0e4f4</td>\n",
              "      <td>object_class</td>\n",
              "      <td>circle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:52:10.752764'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0a2c19be-9a40-47bd-8348-4db9afea62a6</td>\n",
              "      <td>594fcdba-c3dc-4fad-b1c1-f5f537e1d16c</td>\n",
              "      <td>pixel_location</td>\n",
              "      <td>POLYGON ((470 650, 634 650, 634 775, 470 775, 470 650))</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:52:10.752946'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3f66eefe-a26b-479e-abd0-e9dd3d96b826</td>\n",
              "      <td>df10b67d-b476-4c4d-acc2-c1deb5a0e4f4</td>\n",
              "      <td>object_class</td>\n",
              "      <td>rectangle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:52:10.753020'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><br> shape: (22, 7)</td></th><th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">Data Files</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_file_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>filename</th>\n",
              "      <th>split</th>\n",
              "      <th>extra_fields</th>\n",
              "      <th>assessment_id</th>\n",
              "      <th>hash_signature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>3.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131303.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>1.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131251.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>2.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131255.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>0.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131243.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><br> shape: (4, 8)</td></th>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_dataset(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "source": [
        "# Initalize A Highlighter Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7",
        "outputId": "a7e396ed-af38-455d-a026-a44d6e593871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://silverpond-research.staging-highlighter.ai/graphql: [508b...]\n"
          ]
        }
      ],
      "source": [
        "api_token = \"ADD API TOKEN HERE\"  # See https://highlighter-docs.netlify.app/docs/how-to-guides/highlighter-credentials/ for more info\n",
        "endpoint_url = \"https://<YOUR ACCOUNT SUB DOMAIN>.highlighter.ai/graphql\"\n",
        "\n",
        "\n",
        "client = hl.HLClient.from_credential(api_token=api_token, endpoint_url=endpoint_url)\n",
        "print(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8",
      "metadata": {
        "id": "8"
      },
      "source": [
        "# Upload The Images To A Data Source\n",
        "\n",
        "**First create a Data Source in the Highlighter Web UI, note the id and come back**\n",
        "\n",
        "You can find the ID in the URL\n",
        "\n",
        "```\n",
        "https://compuglobalhypermeganet.highlighter.ai/data_sources/#####\n",
        "                                                            ^^^^^\n",
        "                                                              |\n",
        "                                Data Source ID -----------------\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9",
        "outputId": "40eccb4a-a981-4cee-9dbb-25b48082a778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ImageTypeConnection: 200it [00:00, 201.22it/s]\n"
          ]
        }
      ],
      "source": [
        "data_source_id = ToDo\n",
        "\n",
        "_ = ds.upload_data_files(client, data_source_id, data_file_dir=DATA_FILES_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "10",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "10",
        "outputId": "3515b814-4667-46d3-fb16-ff1a1c86823f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">Annotations</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_file_id</th>\n",
              "      <th>entity_id</th>\n",
              "      <th>attribute_id</th>\n",
              "      <th>attribute_name</th>\n",
              "      <th>value</th>\n",
              "      <th>confidence</th>\n",
              "      <th>extra_fields</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10754847</td>\n",
              "      <td>06aa92af-7e51-4e8d-9d60-fec8c9c03b2b</td>\n",
              "      <td>df10b67d-b476-4c4d-acc2-c1deb5a0e4f4</td>\n",
              "      <td>object_class</td>\n",
              "      <td>rectangle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:33:31.272767'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10754847</td>\n",
              "      <td>06aa92af-7e51-4e8d-9d60-fec8c9c03b2b</td>\n",
              "      <td>594fcdba-c3dc-4fad-b1c1-f5f537e1d16c</td>\n",
              "      <td>pixel_location</td>\n",
              "      <td>POLYGON ((468 484, 592 484, 592 615, 468 615, 468 484))</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:33:31.277087'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10754848</td>\n",
              "      <td>0a2c19be-9a40-47bd-8348-4db9afea62a6</td>\n",
              "      <td>df10b67d-b476-4c4d-acc2-c1deb5a0e4f4</td>\n",
              "      <td>object_class</td>\n",
              "      <td>circle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:33:31.277284'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10754848</td>\n",
              "      <td>0a2c19be-9a40-47bd-8348-4db9afea62a6</td>\n",
              "      <td>594fcdba-c3dc-4fad-b1c1-f5f537e1d16c</td>\n",
              "      <td>pixel_location</td>\n",
              "      <td>POLYGON ((470 650, 634 650, 634 775, 470 775, 470 650))</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:33:31.277722'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10754846</td>\n",
              "      <td>3f66eefe-a26b-479e-abd0-e9dd3d96b826</td>\n",
              "      <td>df10b67d-b476-4c4d-acc2-c1deb5a0e4f4</td>\n",
              "      <td>object_class</td>\n",
              "      <td>rectangle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'time': '2024-03-28T03:33:31.277849'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><br> shape: (22, 7)</td></th><th style=\"text-align:center\"><td style=\"vertical-align:top\"><h2 style=\"text-align: center;\">Data Files</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_file_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>filename</th>\n",
              "      <th>split</th>\n",
              "      <th>extra_fields</th>\n",
              "      <th>assessment_id</th>\n",
              "      <th>hash_signature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10754847</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>/tmp/tmp6ksrcbht/sample_dataset/images/3.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131303.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10754848</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>/tmp/tmp6ksrcbht/sample_dataset/images/1.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131251.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10754846</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>/tmp/tmp6ksrcbht/sample_dataset/images/2.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131255.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10754849</td>\n",
              "      <td>1044</td>\n",
              "      <td>1392</td>\n",
              "      <td>/tmp/tmp6ksrcbht/sample_dataset/images/0.jpg</td>\n",
              "      <td>data</td>\n",
              "      <td>{'filename_original': 'IMG_20190415_131243.jpg'}</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"><br> shape: (4, 8)</td></th>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_dataset(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "source": [
        "# Create Object Classes\n",
        "\n",
        "Here we map the class names in the source dataset to Highlighter ObjectClass uuids. We will create\n",
        "them in Highlighter if one of the same name does not already exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "12",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12",
        "outputId": "ff6adfba-e271-45b4-cc5d-401781611e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ObjectClassTypeConnection: 200it [00:00, 202.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rectangle': 4545..a45d|rectangle, 'circle': 9971..99a3|circle, 'triangle': beb4..8c7f|triangle}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get the unique object class names\n",
        "adf = ds.annotations_df\n",
        "object_class_names = adf[adf.attribute_id == str(hl.OBJECT_CLASS_ATTRIBUTE_UUID)].value.unique()\n",
        "\n",
        "# This function checks if object classes exist by of the same name\n",
        "# and is case incentive before creating them. Then returns a dict mapping\n",
        "# the original name to the Highlighter ObjectClass.uuid\n",
        "object_class_name_to_highlighter_uuid = hl.object_classes.create_object_classes(client, object_class_names)\n",
        "print(object_class_name_to_highlighter_uuid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13",
      "metadata": {
        "id": "13"
      },
      "source": [
        "# Create Workflow\n",
        "The Workflow is where we store the annotations for a set of `data_files`. *In our case these data_files are images*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14",
      "metadata": {
        "tags": [],
        "id": "14"
      },
      "outputs": [],
      "source": [
        "# If you already have a workflow_id set it here, if not leave as None\n",
        "workflow_id = ToDo\n",
        "\n",
        "if workflow_id is None:\n",
        "\n",
        "    # Create an Workflow\n",
        "    # Note: Workflow names must be unique\n",
        "    workflow_name = \"My Toy workflow 000\"\n",
        "\n",
        "    workflow = hl.create_workflow(client, name=workflow_name,\n",
        "                             object_class_uuids=[str(i) for i in object_class_name_to_highlighter_uuid.values()])\n",
        "    workflow_id = workflow.id\n",
        "    print(workflow)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15",
      "metadata": {
        "tags": [],
        "id": "15"
      },
      "outputs": [],
      "source": [
        "from highlighter.datasets.formats.highlighter.writer import HighlighterAssessmentsWriter\n",
        "\n",
        "# Define the Dataset Writer\n",
        "writer = HighlighterAssessmentsWriter(client,\n",
        "                                      workflow_id,\n",
        "                                      object_class_uuid_lookup=object_class_name_to_highlighter_uuid\n",
        "                                      )\n",
        "\n",
        "writer.write(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16",
      "metadata": {
        "id": "16"
      },
      "outputs": [],
      "source": [
        "ds.annotations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17",
      "metadata": {
        "id": "17"
      },
      "source": [
        "**Your data should now be visible in the Workflow you defined**\n",
        "\n",
        "Below are some extra credit tutorials\n",
        "\n",
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18",
      "metadata": {
        "id": "18"
      },
      "source": [
        "# Create Dataset From A Custom Format\n",
        "\n",
        "Many times you will be uploading data from a non standard format. The dataset we're working with is in\n",
        "the popular Coco format which **is** supported by Highlighter. However, for the purpose of the exercisewe'll\n",
        "do this manually.\n",
        "\n",
        "The below code block loops through each image and creates a list of `ImagRecord`s then loops through each annotation and creates a list of `AttributeRecord`s. The `ImageRecord`s are pretty straight forward, but let us focus on the `AttributeRecord`s\n",
        "\n",
        "In its simplest form each `AttributeRecord` requres:\n",
        "  - `data_file_id`: This indicates the image the attribute belongs to\n",
        "  - `value`: This is the value of the attribute, and\n",
        "  - `entity_id`: This uniquely identifies an individual object or \"thing\" in an image or even across time or data sources. For example, in the block below we delibrately use the same `entity_id` for both the `PixelLocationAttributeValue` and `ObjectClassAttributeValue`. This tells Highlighter both attributes refer to the same \"thing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19",
      "metadata": {
        "id": "19"
      },
      "outputs": [],
      "source": [
        "COCO_JSON, DATA_FILES_DIR = get_sample_data()\n",
        "\n",
        "api_token = os.environ[\"HL_WEB_GRAPHQL_API_TOKEN\"]\n",
        "endpoint_url = os.environ[\"HL_WEB_GRAPHQL_ENDPOINT\"]\n",
        "client = hl.HLClient.from_credential(api_token=api_token, endpoint_url=endpoint_url)\n",
        "print(client)\n",
        "\n",
        "workflow_id = ToDo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20",
      "metadata": {
        "id": "20"
      },
      "outputs": [],
      "source": [
        "from highlighter import read_object_classes, LabeledUUID\n",
        "from highlighter.datasets.base_models import (\n",
        "    ObjectClassAttributeValue,\n",
        "    PixelLocationAttributeValue,\n",
        "    AttributeRecord,\n",
        "    ImageRecord\n",
        ")\n",
        "\n",
        "with open(COCO_JSON, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Get a lookup to map class names to object class uuids\n",
        "object_class_uuid_lookup = {o.name: o.uuid for o in read_object_classes(client, process_id=workflow_id)}\n",
        "cat_id_to_name = {c[\"id\"]: c[\"name\"] for c in data[\"categories\"]}\n",
        "\n",
        "# We use the ImageRecord BaseModel to validate the fields\n",
        "# before adding them to the Dataset.\n",
        "data_file_records = [ImageRecord(data_file_id=i[\"id\"],\n",
        "                             width=i[\"width\"],\n",
        "                             height=i[\"height\"],\n",
        "                             filename=i[\"file_name\"],\n",
        "                            ) for i in data[\"images\"]]\n",
        "\n",
        "attribute_records = []\n",
        "for a in data[\"annotations\"]:\n",
        "    entity_id = str(uuid4())\n",
        "\n",
        "    # Create an AttributeRecord with an ObjectClassAttributeValue by:\n",
        "    #   - looking up the object_class_uuid from a dict\n",
        "    #   - creating an LabeledUUID for the object class value. You can use LabeledUUID\n",
        "    #     or UUID interchangably. LabeledUUID is simply used to make things readable\n",
        "    #   - Append the AttributeRecord to attribute_records\n",
        "    object_class_name = cat_id_to_name[a[\"category_id\"]]\n",
        "    object_class_uuid = object_class_uuid_lookup[object_class_name]\n",
        "    object_class_value = LabeledUUID(object_class_uuid, label=object_class_name)\n",
        "    object_class_attribute_value = ObjectClassAttributeValue(value=object_class_value)\n",
        "\n",
        "    attribute_records.append(\n",
        "        AttributeRecord.from_attribute_value(\n",
        "            a[\"image_id\"],\n",
        "            object_class_attribute_value,\n",
        "            entity_id=entity_id,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Create an AttributeRecord with an PixelLocationAttributeValue by:\n",
        "    #   - using the PixelLocationAttributeValue helper function to from_left_top_width_height_coords\n",
        "    #   - Append the AttributeRecord to attribute_records\n",
        "    pixel_location_attribute_value = PixelLocationAttributeValue.from_left_top_width_height_coords(a[\"bbox\"])\n",
        "\n",
        "    # Create an PixelLocation AttributeValue\n",
        "    attribute_records.append(\n",
        "        AttributeRecord.from_attribute_value(\n",
        "            a[\"image_id\"],\n",
        "            pixel_location_attribute_value,\n",
        "            entity_id=entity_id,\n",
        "        )\n",
        "    )\n",
        "\n",
        "ds = Dataset(attribute_records=attribute_records, data_file_records=data_file_records)\n",
        "\n",
        "# Upload files as needed and update data_file_ids\n",
        "_ = ds.upload_data_files(client, data_source_id, data_file_dir=DATA_FILES_DIR)\n",
        "\n",
        "show_dataset(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21",
      "metadata": {
        "id": "21"
      },
      "outputs": [],
      "source": [
        "from highlighter.datasets.formats.highlighter.writer import HighlighterAssessmentsWriter\n",
        "\n",
        "# Define the Dataset Writer\n",
        "writer = HighlighterAssessmentsWriter(client,\n",
        "                                      workflow_id)\n",
        "writer.write(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22",
      "metadata": {
        "id": "22"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Create Submissions By Performing Inference On Images In Highlighter\n",
        "\n",
        "Finally. If you have images alread stored in Highligher and you want to do predictions on those images and upload the results to Highligher you can follow a similar process, but without the needing to create `ImageRecords` becuause the images are already in Highlighter.\n",
        "\n",
        "We assume we're looping over a directory of image files with their filename matching their Highlighter `data_file_id`. To set this up we're going to create a directory containing symlinks `<data_file_id>.jpg` that refer to the original image paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23",
      "metadata": {
        "id": "23"
      },
      "outputs": [],
      "source": [
        "symlink_dir: Path = DATA_FILES_DIR.parent / \"hl_id_symlinks\"\n",
        "symlink_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for data_file_id, filename in ds.data_files_df.loc[:, [\"data_file_id\", \"filename\"]].values:\n",
        "    original_file_path = Path(filename)\n",
        "    link_path = symlink_dir / f\"{data_file_id}{original_file_path.suffix}\"\n",
        "    assert original_file_path.absolute().exists()\n",
        "    link_path.hardlink_to(original_file_path.absolute())\n",
        "\n",
        "!ls {symlink_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24",
      "metadata": {
        "id": "24"
      },
      "outputs": [],
      "source": [
        "COCO_JSON, DATA_FILES_DIR = get_sample_data()\n",
        "\n",
        "api_token = os.environ[\"HL_WEB_GRAPHQL_API_TOKEN\"]\n",
        "endpoint_url = os.environ[\"HL_WEB_GRAPHQL_ENDPOINT\"]\n",
        "client = hl.HLClient.from_credential(api_token=api_token, endpoint_url=endpoint_url)\n",
        "print(client)\n",
        "\n",
        "workflow_id = ToDo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25",
      "metadata": {
        "id": "25"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import List\n",
        "from uuid import uuid4\n",
        "from highlighter import read_object_classes, HLClient\n",
        "from highlighter.datasets.base_models import (\n",
        "    ObjectClassAttributeValue,\n",
        "    PixelLocationAttributeValue,\n",
        "    AttributeRecord,\n",
        "    ImageRecord\n",
        ")\n",
        "from highlighter import io\n",
        "\n",
        "\n",
        "class MyAwesomeShapePredictor():\n",
        "\n",
        "    def __init__(self, object_class_uuids):\n",
        "        self.object_class_uuids = object_class_uuids\n",
        "\n",
        "\n",
        "    def convert_output_to_attribute_records(self, raw_model_output: tuple, image_id: int) -> List[AttributeRecord]:\n",
        "\n",
        "        bbox, class_id, conf = raw_model_output\n",
        "\n",
        "        object_class_uuid = self.object_class_uuids[class_id]\n",
        "        object_class_attribute_value = ObjectClassAttributeValue(value=object_class_uuid,\n",
        "                                                                 confidence=conf)\n",
        "\n",
        "        bbox_attribtue_value = PixelLocationAttributeValue.from_left_top_width_height_coords(bbox,\n",
        "                                                                                             confidence=conf)\n",
        "\n",
        "        entity_id = uuid4()\n",
        "        attribute_records: List[AttributeRecord] = [\n",
        "\n",
        "            AttributeRecord.from_attribute_value(\n",
        "            image_id,\n",
        "            object_class_attribute_value,\n",
        "            entity_id=entity_id,\n",
        "            ),\n",
        "\n",
        "            AttributeRecord.from_attribute_value(\n",
        "            image_id,\n",
        "            bbox_attribtue_value,\n",
        "            entity_id=entity_id,\n",
        "            ),\n",
        "\n",
        "        ]\n",
        "\n",
        "        return attribute_records\n",
        "\n",
        "\n",
        "\n",
        "    def get_mock_predictions(self, image):\n",
        "\n",
        "        random_x = np.random.randint(0, image.shape[1]/2)\n",
        "        random_y = np.random.randint(0, image.shape[0]/2)\n",
        "        random_w = np.random.randint(0, image.shape[1]/2)\n",
        "        random_h = np.random.randint(0, image.shape[0]/2)\n",
        "        random_bbox = (random_x, random_y, random_w, random_h)\n",
        "\n",
        "        random_class_id = np.random.randint(low=0, high=len(self.object_class_uuids))\n",
        "        random_conf = np.random.uniform()\n",
        "        return (random_bbox, random_class_id, random_conf)\n",
        "\n",
        "    def predict(self, image_path: Path):\n",
        "        image_id = image_path.stem\n",
        "        image_np = io.read_image(image_path)\n",
        "        raw_model_output = self.get_mock_predictions(image_np)\n",
        "        attribute_records = self.convert_output_to_attribute_records(raw_model_output, image_id)\n",
        "        return attribute_records\n",
        "\n",
        "client = HLClient.from_env()\n",
        "object_class_uuids = [o.uuid for o in read_object_classes(client, process_id=workflow_id)]\n",
        "predictor = MyAwesomeShapePredictor(object_class_uuids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26",
      "metadata": {
        "id": "26"
      },
      "outputs": [],
      "source": [
        "\n",
        "attribute_records: List[AttributeRecord] = []\n",
        "for image_path in symlink_dir.glob(\"*.jpg\"):\n",
        "\n",
        "    records = predictor.predict(image_path)\n",
        "    attribute_records.extend(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27",
      "metadata": {
        "id": "27"
      },
      "outputs": [],
      "source": [
        "ds = Dataset(attribute_records=attribute_records)\n",
        "show_dataset(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28",
      "metadata": {
        "id": "28"
      },
      "outputs": [],
      "source": [
        "from highlighter.datasets.formats.highlighter.writer import HighlighterAssessmentsWriter\n",
        "\n",
        "# Define the Dataset Writer\n",
        "writer = HighlighterAssessmentsWriter(client,\n",
        "                                      workflow_id,\n",
        "                                        )\n",
        "\n",
        "writer.write(ds)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}